{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means++\n",
    "\n",
    "In this notebook, we are going to implement [k-means++](https://en.wikipedia.org/wiki/K-means%2B%2B) algorithm with multiple initial sets. The original k-means++ algorithm will just sample one set of initial centroid points and iterate until the result converges. The only difference in this implementation is that we will sample `RUNS` sets of initial centroid points and update them in parallel. The procedure will finish when all centroid sets are converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Definition of some global parameters.\n",
    "K = 5  # Number of centroids\n",
    "RUNS = 25  # Number of K-means runs that are executed in parallel. Equivalently, number of sets of initial points\n",
    "RANDOM_SEED = 60295531\n",
    "converge_dist = 0.1 # The K-means algorithm is terminated when the change in the location \n",
    "                    # of the centroids is smaller than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from numpy.linalg import norm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def print_log(s):\n",
    "    sys.stdout.write(s + \"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def parse_data(row):\n",
    "    '''\n",
    "    Parse each pandas row into a tuple of (station_name, feature_vec),\n",
    "    where feature_vec is the concatenation of the projection vectors\n",
    "    of TAVG, TRANGE, and SNWD.\n",
    "    '''\n",
    "    return (row[0],  # station name \n",
    "            np.concatenate([row[1], row[2], row[3]])  # TAVG, TRANGE, and SNWD\n",
    "           ) \n",
    "\n",
    "\n",
    "def compute_entropy(d):\n",
    "    '''\n",
    "    Compute the entropy given the frequency vector `d`\n",
    "    Vectorized \n",
    "    '''\n",
    "    d = np.array(d)\n",
    "    d = 1.0 * d / d.sum()\n",
    "    return -np.sum(d * np.log2(d))\n",
    "\n",
    "\n",
    "def choice(p):\n",
    "    '''\n",
    "    Generates a random sample from [0, len(p)),\n",
    "    where p[i] is the probability associated with i. \n",
    "    '''\n",
    "    random = np.random.random()\n",
    "    r = 0.0\n",
    "    for idx in range(len(p)):\n",
    "        r = r + p[idx]\n",
    "        if r > random:\n",
    "            return idx\n",
    "    assert(False)\n",
    "\n",
    "\n",
    "def kmeans_init(rdd, K, RUNS, seed):\n",
    "    '''\n",
    "    Select `RUNS` sets of initial points for `K`-means++\n",
    "    '''\n",
    "    # the `centers` variable is what we want to return\n",
    "    n_data = rdd.count()  # T\n",
    "    shape = rdd.take(1)[0][1].shape[0]  # from parse_data, shape=dim=9\n",
    "    centers = np.zeros((RUNS, K, shape))\n",
    "\n",
    "    def update_dist(vec, dist, k):\n",
    "        new_dist = norm(vec - centers[:, k], axis=1)**2  # col vector \n",
    "        return np.min([dist, new_dist], axis=0)\n",
    "\n",
    "\n",
    "    # The second element `dist` in the tuple below is the closest distance from\n",
    "    # each data point to the selected points in the initial set, where `dist[i]`\n",
    "    # is the closest distance to the points in the i-th initial set (RUNS).\n",
    "\n",
    "    # data point -> dist\n",
    "    data = rdd.map(lambda p: (p, [np.inf]*RUNS)).cache()  \n",
    "    \n",
    "    # Collect the feature vectors of all data points beforehand, might be\n",
    "    # useful in the following for-loop\n",
    "    local_data = rdd.map(lambda (name, vec): vec).collect()\n",
    "    local_data = np.array(local_data)\n",
    "    # Randomly select the FIRST center point for every run of k-means++,\n",
    "    # i.e. randomly select `RUNS` points and add it to the `centers` variable\n",
    "    sample = [local_data[run] for run in np.random.randint(0, len(local_data), RUNS)]\n",
    "    centers[:, 0] = sample  # shape: (RUNS, K, shape), the first \n",
    "    \n",
    "    \n",
    "    # after selecting the first centroid, select the remaining \n",
    "    for idx in range(K - 1):\n",
    "        ##############################################################################\n",
    "        # Insert your code here:\n",
    "        ##############################################################################\n",
    "        # In each iteration, you need to select one point for each set\n",
    "        # of initial points (so select `RUNS` points in total).\n",
    "        # For each data point x, let D_i(x) be the distance between x and\n",
    "        # the nearest center that has already been added to the i-th set.\n",
    "        # Choose a new data point for i-th set using a weighted probability\n",
    "        # where point x is chosen with probability proportional to D_i(x)^2\n",
    "        ##############################################################################      \n",
    "        c = idx\n",
    "        c_new = c + 1  # choosing the i-th centroid \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Numpy Vectorization\n",
    "        dp = np.repeat(local_data[np.newaxis, :], RUNS, axis=0)\n",
    "        dist = np.zeros((RUNS, n_data), dtype=np.float64) + np.inf\n",
    "        for c in xrange(c_new):  # No Need, consider loop invariant, min_dist\n",
    "            new_dist = norm(dp - np.repeat(centers[:, c][:, np.newaxis], n_data, axis=1), axis=2)**2  # col vector \n",
    "            dist = np.minimum(dist, new_dist)\n",
    "\n",
    "        ## Naive \n",
    "        #for t in xrange(n_data):\n",
    "        #    dist[:, t] = update_dist(dp[:, t], dist[:, t], c)\n",
    "\n",
    "        ## Spark\n",
    "        #data = data.map(lambda (p, dist): (p, update_dist(p[1], dist, c)))  # p[1] is the vec\n",
    "        #dist = np.array(data.values().collect()).T\n",
    "        \n",
    "        assert dist.shape[0] == RUNS\n",
    "        dist_sum = np.sum(dist, axis=1)\n",
    "        P = np.divide(dist, np.repeat(dist_sum[:, np.newaxis], n_data, axis=1))\n",
    "        \n",
    "        for r in xrange(RUNS):\n",
    "            i = choice(P[r])            \n",
    "            centers[r, c_new] = local_data[i]\n",
    "\n",
    "    return centers\n",
    "\n",
    "\n",
    "def get_closest(p, centers):\n",
    "    '''\n",
    "    Return the indices the nearest centroids of `p`.\n",
    "    `centers` contains sets of centroids, where `centers[r]` is\n",
    "    the r-th set of centroids. (RUNS)\n",
    "    '''\n",
    "    best = [0] * len(centers)\n",
    "    closest = [np.inf] * len(centers)\n",
    "    for r in range(len(centers)):\n",
    "        for k in range(len(centers[0])):\n",
    "            temp_dist = norm(p - centers[r][k])\n",
    "            if temp_dist < closest[r]:\n",
    "                closest[r] = temp_dist\n",
    "                best[r] = k\n",
    "    return best\n",
    "\n",
    "\n",
    "def kmeans(rdd, K, RUNS, converge_dist, seed):\n",
    "    '''\n",
    "    Run K-means++ algorithm on `rdd`, where `RUNS` is the number of\n",
    "    initial sets to use.\n",
    "    '''\n",
    "    k_points = kmeans_init(rdd, K, RUNS, seed)\n",
    "    print_log(\"Initialized.\")\n",
    "    temp_dist = 1.0\n",
    "\n",
    "    iters = 0\n",
    "    st = time.time()\n",
    "    \n",
    "    n_data = rdd.count()  # T\n",
    "    shape = rdd.take(1)[0][1].shape[0]  # from parse_data, shape=dim=3\n",
    "    local_data_rdd = rdd.map(lambda (name, vec): vec).cache()\n",
    "    local_data = np.array(local_data_rdd.collect())\n",
    "    \n",
    "    while temp_dist > converge_dist:\n",
    "        ##############################################################################\n",
    "        # INSERT YOUR CODE HERE\n",
    "        ##############################################################################\n",
    "        \n",
    "        # Update all `RUNS` sets of centroids using standard k-means algorithm\n",
    "        # Outline:\n",
    "        #   - For each point x, select its nearest centroid in i-th centroids set\n",
    "        #   - Average all points that are assigned to the same centroid\n",
    "        #   - Update the centroid with the average of all points that are assigned to it\n",
    "        \n",
    "        # Insert your code here\n",
    "        new_points = {}\n",
    "        \n",
    "        ## Numpy vectorization\n",
    "        # C = np.apply_along_axis(lambda x: get_closest(x, k_points), 1, local_data)        \n",
    "        \n",
    "        ## Naive\n",
    "        #for t in xrange(n_data):\n",
    "        #    c = get_closest(local_data[t], k_points)\n",
    "        #    for r, k in enumerate(c):\n",
    "        #        cluster[(r, k)].append(local_data[t])\n",
    "        \n",
    "        ## Spark \n",
    "        C = local_data_rdd.map(lambda x: get_closest(x, k_points))\n",
    "        C = np.array(C.collect())\n",
    "        assert C.shape[0] == n_data\n",
    "        for r in xrange(RUNS):\n",
    "            for k in xrange(K):\n",
    "                cluster_dp = local_data[C[:, r]==k]\n",
    "                new_points[(r, k)] = cluster_dp.mean(axis=0)\n",
    "    \n",
    "        # You can modify this statement as long as `temp_dist` equals to\n",
    "        # max( sum( l2_norm of the movement of j-th centroid in each centroids set ))\n",
    "        ##############################################################################\n",
    "        temp_dist = np.max([\n",
    "                np.sum([norm(k_points[r, k] - new_points[(r, k)]) for k in range(K)])\n",
    "                for r in range(RUNS)\n",
    "        ])   # move distance, max over all runs & all points \n",
    "\n",
    "        iters = iters + 1\n",
    "        if iters % 5 == 0:\n",
    "            print_log(\"Iteration %d max shift: %.2f (time: %.2f)\" %\n",
    "                      (iters, temp_dist, time.time() - st))\n",
    "            st = time.time()\n",
    "\n",
    "        # update old centroids\n",
    "        # You modify this for-loop to meet your need\n",
    "        for ((r, k), p) in new_points.items():  ## pattern matching in python dict\n",
    "            k_points[r, k] = p\n",
    "\n",
    "    return k_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'USC00044534', array([  3.04796236e+03,   1.97434852e+03,   1.50560792e+02,\n",
       "          -2.90363288e+03,  -2.36907268e+02,   1.47021791e+02,\n",
       "           1.91503001e-01,   1.87262808e-01,  -4.01379553e-02]))]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read data\n",
    "data = pickle.load(open(\"../../Data/Weather/stations_projections.pickle\", \"rb\"))\n",
    "rdd = sc.parallelize([parse_data(row[1]) for row in data.iterrows()])\n",
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized.\n",
      "Iteration 5 max shift: 3211.03 (time: 18.60)\n",
      "Iteration 10 max shift: 1928.05 (time: 19.14)\n",
      "Iteration 15 max shift: 693.41 (time: 19.55)\n",
      "Iteration 20 max shift: 348.29 (time: 19.62)\n",
      "Iteration 25 max shift: 235.29 (time: 25.48)\n",
      "Iteration 30 max shift: 185.35 (time: 19.09)\n",
      "Iteration 35 max shift: 51.71 (time: 18.13)\n",
      "Iteration 40 max shift: 45.07 (time: 18.65)\n",
      "Iteration 45 max shift: 26.03 (time: 19.55)\n",
      "Iteration 50 max shift: 15.59 (time: 19.59)\n",
      "Iteration 55 max shift: 0.85 (time: 18.38)\n",
      "Time takes to converge: 224.243620157\n"
     ]
    }
   ],
   "source": [
    "# main code\n",
    "\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "centroids = kmeans(rdd, K, RUNS, converge_dist, np.random.randint(1000))\n",
    "group = rdd.mapValues(lambda p: get_closest(p, centroids)) \\\n",
    "           .collect()\n",
    "\n",
    "print \"Time takes to converge:\", time.time() - st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify your results\n",
    "Verify your results by computing the objective function of the k-means clustering problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cost(rdd, centers):\n",
    "    '''\n",
    "    Compute the square of l2 norm from each data point in `rdd`\n",
    "    to the centroids in `centers`\n",
    "    '''\n",
    "    def _get_cost(p, centers):\n",
    "        best = [0] * len(centers)\n",
    "        closest = [np.inf] * len(centers)\n",
    "        for idx in range(len(centers)):\n",
    "            for j in range(len(centers[0])):\n",
    "                temp_dist = norm(p - centers[idx][j])\n",
    "                if temp_dist < closest[idx]:\n",
    "                    closest[idx] = temp_dist\n",
    "                    best[idx] = j\n",
    "        return np.array(closest)**2\n",
    "    \n",
    "    cost = rdd.map(lambda (name, v): _get_cost(v, centroids)).collect()\n",
    "    return np.array(cost).sum(axis=0)\n",
    "\n",
    "cost = get_cost(rdd, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.8254902123 33.7575332525 33.7632782289\n"
     ]
    }
   ],
   "source": [
    "log2 = np.log2\n",
    "\n",
    "print log2(np.max(cost)), log2(np.min(cost)), log2(np.mean(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the increase of entropy after multiple runs of k-means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entropy = []\n",
    "\n",
    "for i in range(RUNS):\n",
    "    count = {}\n",
    "    for g, sig in group:\n",
    "        _s = ','.join(map(str, sig[:(i + 1)]))\n",
    "        count[_s] = count.get(_s, 0) + 1\n",
    "    entropy.append(compute_entropy(count.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Remove this cell before submitting to PyBolt (PyBolt does not fully support matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9657287651773423"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEPCAYAAABCyrPIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67df784110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.plot(range(1, RUNS + 1), entropy)\n",
    "2**entropy[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy= [1.6445469704935676, 1.6445469704935676, 2.0674170627025292, 2.0674170627025297, 2.0674170627025292, 2.0674170627025297, 2.0674170627025297, 2.0674170627025301, 2.0674170627025297, 2.0674170627025297, 2.0674170627025301, 2.0674170627025297, 2.0674170627025297, 2.0674170627025297, 2.1640389721727686, 2.1640389721727686, 2.1640389721727686, 2.1640389721727686, 2.1640389721727686, 2.1640389721727691, 2.2079748799839716, 2.207974879983972, 2.3120054617120385, 2.3120054617120385, 2.312005461712038]\n",
      "best_centers= [array([ 1492.0570036 ,  1954.30230067,    94.48584365, -2567.99675086,\n",
      "        -112.2682711 ,   152.28015089,   395.84574671,   131.09390181,\n",
      "          73.10315542]), array([   408.29696084,   1353.92836359,     56.37619358,  -2206.17029272,\n",
      "         -221.37785013,    183.25193705,  18757.57406286,  -5513.4828535 ,\n",
      "         1476.58182765]), array([ 2952.76608   ,  1933.02980077,    92.424188  , -2547.74851278,\n",
      "         144.84123959,   154.0172669 ,    18.40817384,     7.84926361,\n",
      "           5.11113863]), array([  750.10763916,  2067.97627806,    35.34601332, -2398.58742321,\n",
      "        -138.36631381,   233.32209536,  2268.85311051,   245.99611499,\n",
      "         125.46432194]), array([  428.4738994 ,  1807.58033164,    35.14799298, -2574.43476306,\n",
      "        -180.39839191,   263.09089521,  6048.90511888,  -743.20856056,\n",
      "         256.68319372])]\n"
     ]
    }
   ],
   "source": [
    "print 'entropy=',entropy\n",
    "best = np.argmin(cost)\n",
    "print 'best_centers=',list(centroids[best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
