{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means++\n",
    "\n",
    "In this notebook, we are going to implement [k-means++](https://en.wikipedia.org/wiki/K-means%2B%2B) algorithm with multiple initial sets. The original k-means++ algorithm will just sample one set of initial centroid points and iterate until the result converges. The only difference in this implementation is that we will sample `RUNS` sets of initial centroid points and update them in parallel. The procedure will finish when all centroid sets are converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Name: Danyang Zhangn\n",
    "# Email: daz040@eng.ucsd.edu\n",
    "# PID: A53104006\n",
    "PYBOLT = False\n",
    "if PYBOLT:\n",
    "    from pyspark import SparkContext\n",
    "    sc = SparkContext()\n",
    "\n",
    "### Definition of some global parameters.\n",
    "K = 5  # Number of centroids\n",
    "RUNS = 25  # Number of K-means runs that are executed in parallel. Equivalently, number of sets of initial points\n",
    "RANDOM_SEED = 60295531\n",
    "converge_dist = 0.1 # The K-means algorithm is terminated when the change in the location \n",
    "                    # of the centroids is smaller than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from numpy.linalg import norm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def print_log(s):\n",
    "    sys.stdout.write(s + \"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def parse_data(row):\n",
    "    '''\n",
    "    Parse each pandas row into a tuple of (station_name, feature_vec),\n",
    "    where feature_vec is the concatenation of the projection vectors\n",
    "    of TAVG, TRANGE, and SNWD.\n",
    "    '''\n",
    "    return (row[0],  # station name \n",
    "            np.concatenate([row[1], row[2], row[3]])  # TAVG, TRANGE, and SNWD\n",
    "           ) \n",
    "\n",
    "\n",
    "def compute_entropy(d):\n",
    "    '''\n",
    "    Compute the entropy given the frequency vector `d`\n",
    "    Vectorized \n",
    "    '''\n",
    "    d = np.array(d)\n",
    "    d = 1.0 * d / d.sum()\n",
    "    return -np.sum(d * np.log2(d))\n",
    "\n",
    "\n",
    "def choice(p):\n",
    "    '''\n",
    "    Generates a random sample from [0, len(p)),\n",
    "    where p[i] is the probability associated with i. \n",
    "    '''\n",
    "    random = np.random.random()\n",
    "    r = 0.0\n",
    "    for idx in range(len(p)):\n",
    "        r = r + p[idx]\n",
    "        if r > random:\n",
    "            return idx\n",
    "    assert(False)\n",
    "\n",
    "\n",
    "def kmeans_init(rdd, K, RUNS, seed):\n",
    "    '''\n",
    "    Select `RUNS` sets of initial points for `K`-means++\n",
    "    '''\n",
    "    # the `centers` variable is what we want to return\n",
    "    n_data = rdd.count()  # T\n",
    "    shape = rdd.take(1)[0][1].shape[0]  # from parse_data, shape=dim=9\n",
    "    centers = np.zeros((RUNS, K, shape))\n",
    "\n",
    "    def update_dist(vec, dist, k):\n",
    "        new_dist = norm(vec - centers[:, k], axis=1)**2  # col vector \n",
    "        return np.min([dist, new_dist], axis=0)\n",
    "\n",
    "\n",
    "    # The second element `dist` in the tuple below is the closest distance from\n",
    "    # each data point to the selected points in the initial set, where `dist[i]`\n",
    "    # is the closest distance to the points in the i-th initial set (RUNS).\n",
    "\n",
    "    # data point -> dist\n",
    "    data = rdd.map(lambda p: (p, [np.inf]*RUNS)).cache()  \n",
    "    \n",
    "    # Collect the feature vectors of all data points beforehand, might be\n",
    "    # useful in the following for-loop\n",
    "    local_data = rdd.map(lambda (name, vec): vec).collect()\n",
    "    local_data = np.array(local_data)\n",
    "    # Randomly select the FIRST center point for every run of k-means++,\n",
    "    # i.e. randomly select `RUNS` points and add it to the `centers` variable\n",
    "    sample = [local_data[run] for run in np.random.randint(0, len(local_data), RUNS)]\n",
    "    centers[:, 0] = sample  # shape: (RUNS, K, shape), the first \n",
    "    \n",
    "    \n",
    "    # after selecting the first centroid, select the remaining \n",
    "    for idx in range(K - 1):\n",
    "        ##############################################################################\n",
    "        # Insert your code here:\n",
    "        ##############################################################################\n",
    "        # In each iteration, you need to select one point for each set\n",
    "        # of initial points (so select `RUNS` points in total).\n",
    "        # For each data point x, let D_i(x) be the distance between x and\n",
    "        # the nearest center that has already been added to the i-th set.\n",
    "        # Choose a new data point for i-th set using a weighted probability\n",
    "        # where point x is chosen with probability proportional to D_i(x)^2\n",
    "        ##############################################################################      \n",
    "        c = idx\n",
    "        c_new = c + 1  # choosing the i-th centroid \n",
    "        \n",
    "        ## Numpy Vectorization\n",
    "        dp = np.repeat(local_data[np.newaxis, :], RUNS, axis=0)\n",
    "        dist = np.zeros((RUNS, n_data), dtype=np.float64) + np.inf\n",
    "        for c in xrange(c_new):  # No Need, consider loop invariant, min_dist\n",
    "            new_dist = norm(dp - np.repeat(centers[:, c][:, np.newaxis], n_data, axis=1), axis=2)**2  # col vector \n",
    "            dist = np.minimum(dist, new_dist)\n",
    "\n",
    "        ## Naive \n",
    "        #for t in xrange(n_data):\n",
    "        #    dist[:, t] = update_dist(dp[:, t], dist[:, t], c)\n",
    "\n",
    "        ## Spark\n",
    "        #data = data.map(lambda (p, dist): (p, update_dist(p[1], dist, c)))  # p[1] is the vec\n",
    "        #dist = np.array(data.values().collect()).T\n",
    "        \n",
    "        assert dist.shape == (RUNS, n_data)\n",
    "        dist_sum = np.sum(dist, axis=1)\n",
    "        P = np.divide(dist, np.repeat(dist_sum[:, np.newaxis], n_data, axis=1))\n",
    "        \n",
    "        ## Naive\n",
    "        #for r in xrange(RUNS):\n",
    "        #    i = choice(P[r])            \n",
    "        #    centers[r, c_new] = local_data[i]\n",
    "        \n",
    "        ## Vectorize for axis of RUNS\n",
    "        i = np.apply_along_axis(choice, 1, P)            \n",
    "        centers[:, c_new] = local_data[i]  # dp: (RUNS, T, dim)\n",
    "\n",
    "    return centers\n",
    "\n",
    "\n",
    "def get_closest(p, centers):\n",
    "    '''\n",
    "    Return the indices the nearest centroids of `p`.\n",
    "    `centers` contains sets of centroids, where `centers[r]` is\n",
    "    the r-th set of centroids. (RUNS)\n",
    "    '''\n",
    "    best = [0] * len(centers)\n",
    "    closest = [np.inf] * len(centers)\n",
    "    for r in range(len(centers)):\n",
    "        for k in range(len(centers[0])):\n",
    "            temp_dist = norm(p - centers[r][k])\n",
    "            if temp_dist < closest[r]:\n",
    "                closest[r] = temp_dist\n",
    "                best[r] = k\n",
    "    return best\n",
    "\n",
    "\n",
    "def kmeans(rdd, K, RUNS, converge_dist, seed):\n",
    "    '''\n",
    "    Run K-means++ algorithm on `rdd`, where `RUNS` is the number of\n",
    "    initial sets to use.\n",
    "    '''\n",
    "    k_points = kmeans_init(rdd, K, RUNS, seed)\n",
    "    print_log(\"Initialized.\")\n",
    "    temp_dist = 1.0\n",
    "\n",
    "    iters = 0\n",
    "    st = time.time()\n",
    "    \n",
    "    n_data = rdd.count()  # T\n",
    "    shape = rdd.take(1)[0][1].shape[0]  # from parse_data, shape=dim=3\n",
    "    local_data_rdd = rdd.map(lambda (name, vec): vec).cache()\n",
    "    local_data = np.array(local_data_rdd.collect())\n",
    "    \n",
    "    while temp_dist > converge_dist:\n",
    "        ##############################################################################\n",
    "        # INSERT YOUR CODE HERE\n",
    "        ##############################################################################\n",
    "        \n",
    "        # Update all `RUNS` sets of centroids using standard k-means algorithm\n",
    "        # Outline:\n",
    "        #   - For each point x, select its nearest centroid in i-th centroids set\n",
    "        #   - Average all points that are assigned to the same centroid\n",
    "        #   - Update the centroid with the average of all points that are assigned to it\n",
    "        \n",
    "        # Insert your code here\n",
    "        new_points = {}\n",
    "        \n",
    "        ## Numpy vectorization\n",
    "        # C = np.apply_along_axis(lambda x: get_closest(x, k_points), 1, local_data)        \n",
    "        \n",
    "        ## Naive\n",
    "        #for t in xrange(n_data):\n",
    "        #    c = get_closest(local_data[t], k_points)\n",
    "        #    for r, k in enumerate(c):\n",
    "        #        cluster[(r, k)].append(local_data[t])\n",
    "        \n",
    "        ## Spark \n",
    "        C = local_data_rdd.map(lambda x: get_closest(x, k_points))\n",
    "        C = np.array(C.collect())\n",
    "        assert C.shape == (n_data, RUNS)  # (t, r) -> cluster label\n",
    "        for r in xrange(RUNS):\n",
    "            for k in xrange(K):\n",
    "                cluster_dp = local_data[C[:, r]==k]  # cluster data point\n",
    "                new_points[(r, k)] = cluster_dp.mean(axis=0)\n",
    "                ## otherwise, spark reduce is slower than collect for numpy due to overhead of reduce\n",
    "    \n",
    "        # You can modify this statement as long as `temp_dist` equals to\n",
    "        # max( sum( l2_norm of the movement of j-th centroid in each centroids set ))\n",
    "        ##############################################################################\n",
    "        temp_dist = np.max([\n",
    "                np.sum([norm(k_points[r, k] - new_points[(r, k)]) for k in range(K)])\n",
    "                for r in range(RUNS)\n",
    "        ])   # move distance, max over all runs & all points \n",
    "\n",
    "        iters = iters + 1\n",
    "        if iters % 5 == 0:\n",
    "            print_log(\"Iteration %d max shift: %.2f (time: %.2f)\" %\n",
    "                      (iters, temp_dist, time.time() - st))\n",
    "            st = time.time()\n",
    "\n",
    "        # update old centroids\n",
    "        # You modify this for-loop to meet your need\n",
    "        for ((r, k), p) in new_points.items():  ## pattern matching in python dict\n",
    "            k_points[r, k] = p\n",
    "\n",
    "    return k_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'USC00044534', array([  3.04796236e+03,   1.97434852e+03,   1.50560792e+02,\n",
       "          -2.90363288e+03,  -2.36907268e+02,   1.47021791e+02,\n",
       "           1.91503001e-01,   1.87262808e-01,  -4.01379553e-02]))]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read data\n",
    "if PYBOLT:\n",
    "    path = \"../Data/Weather/stations_projections.pickle\"\n",
    "else:\n",
    "    path = \"../../Data/Weather/stations_projections.pickle\"\n",
    "    \n",
    "data = pickle.load(open(path, \"rb\"))\n",
    "rdd = sc.parallelize([parse_data(row[1]) for row in data.iterrows()])\n",
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized.\n",
      "Iteration 5 max shift: 3211.03 (time: 18.17)\n",
      "Iteration 10 max shift: 1928.05 (time: 18.50)\n",
      "Iteration 15 max shift: 693.41 (time: 20.11)\n",
      "Iteration 20 max shift: 348.29 (time: 18.88)\n",
      "Iteration 25 max shift: 235.29 (time: 21.06)\n",
      "Iteration 30 max shift: 185.35 (time: 21.69)\n",
      "Iteration 35 max shift: 51.71 (time: 18.65)\n",
      "Iteration 40 max shift: 45.07 (time: 19.68)\n",
      "Iteration 45 max shift: 26.03 (time: 27.65)\n",
      "Iteration 50 max shift: 15.59 (time: 18.25)\n",
      "Iteration 55 max shift: 0.85 (time: 18.88)\n",
      "Time takes to converge: 230.418900013\n"
     ]
    }
   ],
   "source": [
    "# main code\n",
    "\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "centroids = kmeans(rdd, K, RUNS, converge_dist, np.random.randint(1000))\n",
    "group = rdd.mapValues(lambda p: get_closest(p, centroids)) \\\n",
    "           .collect()\n",
    "\n",
    "print \"Time takes to converge:\", time.time() - st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify your results\n",
    "Verify your results by computing the objective function of the k-means clustering problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cost(rdd, centers):\n",
    "    '''\n",
    "    Compute the square of l2 norm from each data point in `rdd`\n",
    "    to the centroids in `centers`\n",
    "    '''\n",
    "    def _get_cost(p, centers):\n",
    "        best = [0] * len(centers)\n",
    "        closest = [np.inf] * len(centers)\n",
    "        for idx in range(len(centers)):\n",
    "            for j in range(len(centers[0])):\n",
    "                temp_dist = norm(p - centers[idx][j])\n",
    "                if temp_dist < closest[idx]:\n",
    "                    closest[idx] = temp_dist\n",
    "                    best[idx] = j\n",
    "        return np.array(closest)**2\n",
    "    \n",
    "    cost = rdd.map(lambda (name, v): _get_cost(v, centroids)).collect()\n",
    "    return np.array(cost).sum(axis=0)\n",
    "\n",
    "cost = get_cost(rdd, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.8254902123 33.7575332525 33.7790236109\n"
     ]
    }
   ],
   "source": [
    "log2 = np.log2\n",
    "\n",
    "print log2(np.max(cost)), log2(np.min(cost)), log2(np.mean(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the increase of entropy after multiple runs of k-means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entropy = []\n",
    "\n",
    "for i in range(RUNS):\n",
    "    count = {}\n",
    "    for g, sig in group:\n",
    "        _s = ','.join(map(str, sig[:(i + 1)]))\n",
    "        count[_s] = count.get(_s, 0) + 1\n",
    "    entropy.append(compute_entropy(count.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Remove this cell before submitting to PyBolt (PyBolt does not fully support matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEPCAYAAABCyrPIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67d5625ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not PYBOLT:\n",
    "    %matplotlib inline\n",
    "\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Entropy\")\n",
    "    plt.plot(range(1, RUNS + 1), entropy)\n",
    "    2**entropy[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy= [1.6445469704935676, 2.0800064512748428, 2.080006451274842, 2.0800064512748424, 2.1906681946052755, 2.2570115065383876, 2.2786597860645408, 2.2786597860645408, 2.2786597860645408, 2.2786597860645408, 2.2786597860645403, 2.2786597860645408, 2.2786597860645408, 2.2786597860645408, 2.2849509629282276, 2.2849509629282276, 2.2849509629282276, 2.2849509629282272, 2.286874405497795, 2.2868744054977945, 2.2868744054977945, 2.286874405497795, 2.2868744054977945, 2.286874405497795, 2.286874405497795]\n",
      "best_centers= [array([ 2952.76608   ,  1933.02980077,    92.424188  , -2547.74851278,\n",
      "         144.84123959,   154.0172669 ,    18.40817384,     7.84926361,\n",
      "           5.11113863]), array([  428.4738994 ,  1807.58033164,    35.14799298, -2574.43476306,\n",
      "        -180.39839191,   263.09089521,  6048.90511888,  -743.20856056,\n",
      "         256.68319372]), array([ 1492.0570036 ,  1954.30230067,    94.48584365, -2567.99675086,\n",
      "        -112.2682711 ,   152.28015089,   395.84574671,   131.09390181,\n",
      "          73.10315542]), array([  750.10763916,  2067.97627806,    35.34601332, -2398.58742321,\n",
      "        -138.36631381,   233.32209536,  2268.85311051,   245.99611499,\n",
      "         125.46432194]), array([   408.29696084,   1353.92836359,     56.37619358,  -2206.17029272,\n",
      "         -221.37785013,    183.25193705,  18757.57406286,  -5513.4828535 ,\n",
      "         1476.58182765])]\n"
     ]
    }
   ],
   "source": [
    "print 'entropy=', entropy\n",
    "best = np.argmin(cost)\n",
    "print 'best_centers=', list(centroids[best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
